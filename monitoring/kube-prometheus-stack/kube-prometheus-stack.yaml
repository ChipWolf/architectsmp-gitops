---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  interval: 5m
  install:
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3
  chart:
    spec:
      # renovate: registryUrl=https://prometheus-community.github.io/helm-charts
      chart: kube-prometheus-stack
      version: 14.0.1
      sourceRef:
        kind: HelmRepository
        name: prometheus-community-charts
        namespace: flux-system
      interval: 5m
  timeout: 20m
  values:
    additionalPrometheusRulesMap:
      uptimerobot:
        groups:
          - name: public
            rules:
              - alert: MinecraftDown
                expr: uptimerobot_status{c1_name="Minecraft"} > 0
                for: 15m
                labels:
                  severity: critical
                annotations:
                  summary: "Minecraft is unreachable"
                  description: "Minecraft has been unreachable from the internet for more than 30 minutes"
              - alert: DynmapDown
                expr: uptimerobot_status{c1_name="Dynmap"} > 0
                for: 30m
                labels:
                  severity: critical
                annotations:
                  summary: "Dynmap is unreachable"
                  description: "Dynmap has been unreachable from the internet for more than 30 minutes"
          - name: services
            rules:
              - alert: ServicesDown
                expr: uptimerobot_status > 0
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: "{{ $labels.c1_name }} is unreachable"
                  description: "{{ $labels.c1_name }} is unreachable from the internet for more than 5 minutes"
    server:
      resources:
        requests:
          memory: 1500Mi
          cpu: 25m
        limits:
          memory: 2000Mi
    prometheusOperator:
      createCustomResource: true
      configReloaderCpu: 200m
    alertmanager:
      alertmanagerSpec:
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: local-path
              resources:
                requests:
                  storage: 10Gi
      ingress:
        enabled: true
        annotations:
          kubernetes.io/ingress.class: "nginx"
          nginx.ingress.kubernetes.io/auth-url: "https://auth.architectsmp.com/oauth2/auth"
          nginx.ingress.kubernetes.io/auth-signin: https://auth.architectsmp.com/oauth2/start
        hosts: [prom-alert.architectsmp.com]
        tls:
          - hosts:
              - prom-alert.architectsmp.com
      config:
        global:
          resolve_timeout: 5m
        route:
          receiver: "slack-notifications"
          routes:
            - match:
                alertname: Watchdog
              receiver: "null"
            - receiver: "pagerduty"
              continue: true
            - receiver: "slack-notifications"
        inhibit_rules:
          - source_match:
              severity: "critical"
            target_match:
              severity: "warning"
            # Apply inhibition if the alertname is the same.
            equal: ["alertname", "namespace"]
        templates: ["*.tmpl"]
      templateFiles:
        pagerduty-custom.tmpl: |-
          {{- define "pagerduty.custom.description" -}}[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ if ne .CommonAnnotations.summary ""}}{{ .CommonAnnotations.summary }}{{ else if ne .CommonAnnotations.message ""}}{{ .CommonAnnotations.message }}{{ else if ne .CommonAnnotations.description ""}}{{ .CommonAnnotations.description }}{{ else }}{{ .CommonLabels.alertname }}{{ end }}{{- end -}}
          {{- define "pagerduty.custom.instances" -}}{{- range $i, $alert := . }}{{- .Annotations.description -}}{{- "\n" -}}{{- end -}}{{- end -}}
    nodeExporter:
      serviceMonitor:
        relabelings:
          - sourceLabels: [__meta_kubernetes_pod_node_name]
            targetLabel: nodename
            action: replace
    grafana:
      enabled: false
    kubeEtcd:
      enabled: false
    kubeControllerManager:
      enabled: false
    kubeScheduler:
      enabled: false
    kubeProxy:
      enabled: false
    prometheus-node-exporter:
      tolerations:
        - key: "node-role.kubernetes.io/master"
          operator: "Exists"
    prometheus:
      ingress:
        enabled: true
        annotations:
          kubernetes.io/ingress.class: "nginx"
          nginx.ingress.kubernetes.io/auth-url: "https://auth.architectsmp.com/oauth2/auth"
          nginx.ingress.kubernetes.io/auth-signin: https://auth.architectsmp.com/oauth2/start
        hosts: [prom-server.architectsmp.com]
        tls:
          - hosts:
              - prom-server.architectsmp.com
      prometheusSpec:
        externalLabels:
          cluster: "default"
        replicas: 1
        replicaExternalLabelName: "replica"
        ruleSelector: {}
        ruleNamespaceSelector: {}
        ruleSelectorNilUsesHelmValues: false
        serviceMonitorSelector: {}
        serviceMonitorNamespaceSelector: {}
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelector: {}
        podMonitorNamespaceSelector: {}
        podMonitorSelectorNilUsesHelmValues: false
        retention: 6h
        enableAdminAPI: true
        walCompression: true
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: local-path
              resources:
                requests:
                  storage: 10Gi
        thanos:
          image: quay.io/thanos/thanos:v0.18.0
          version: v0.17.0
          objectStorageConfig:
            name: thanos
            key: object-store.yaml
  valuesFrom:
    - kind: Secret
      name: "kube-prometheus-stack-helm-values"
      optional: false
